{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "492aebf6",
   "metadata": {},
   "source": [
    "## ``Causal_sampler`` Demo. 02: \n",
    "\n",
    "### Simulation on the semi-synthetic background-MNIST classification task\n",
    "\n",
    "> Front-door confounding\n",
    "\n",
    "Front-door confounding scenario assumes there are multiple latent confounders that affect both the cause and effect variables, while there is a mediator variable that intercepts all direct causal effect from the cause to the effect.\n",
    "\n",
    "In this demonstration, we suppose $Z$ is the mediator, $Y$ is the cause and $X$ is the effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73d3b124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import causal_sampler.pipeline as cs_pipe\n",
    "from scipy.ndimage import maximum_filter\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.family'] = 'Calibri'\n",
    "plt.rcParams[\"xtick.labelsize\"] = 14\n",
    "plt.rcParams[\"ytick.labelsize\"] = 14\n",
    "plt.rcParams[\"axes.labelsize\"] = 14\n",
    "plt.rcParams[\"legend.fontsize\"] = 14\n",
    "plt.rcParams[\"axes.titlesize\"] = 16\n",
    "\n",
    "semisyn_data_dir = r\"../test_data/semi_synthetic_data/frontdoor_data/\"\n",
    "\n",
    "def maxPooling_imgArr(img_flatArr, kernel_size, padding = \"nearest\", flatten = False):\n",
    "    n_imgs = img_flatArr.shape[0]\n",
    "    img_size = int(img_flatArr.shape[1]**0.5)\n",
    "    img_arr = img_flatArr.reshape(n_imgs, img_size, img_size)\n",
    "    resized_imgs = []\n",
    "    for i in range(n_imgs):\n",
    "        resized_imgs.append(maximum_filter(img_arr[i], size=kernel_size, mode=padding)[::kernel_size, ::kernel_size])\n",
    "    resized_imgs = np.array(resized_imgs)\n",
    "    if flatten:\n",
    "        resized_imgs = resized_imgs.reshape(n_imgs, -1)\n",
    "    return resized_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb3169f",
   "metadata": {},
   "source": [
    "0. Define the front-door causal graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7ced8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_graph = '\"Front-door Causal Graph\"; \\\n",
    "                Y; X; Z; \\\n",
    "                Y->Z; \\\n",
    "                Z->X; \\\n",
    "                Y<->X; '"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923687ba",
   "metadata": {},
   "source": [
    "1. Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4640902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_conf = pd.read_csv(semisyn_data_dir + \"X_train_conf.csv\")\n",
    "Y_train_conf = pd.read_csv(semisyn_data_dir + \"Y_train_conf.csv\")\n",
    "Z_train_conf = pd.read_csv(semisyn_data_dir + \"Z_train_conf.csv\")\n",
    "X_train_conf = np.array(X_train_conf)\n",
    "X_train_conf = maxPooling_imgArr(X_train_conf, kernel_size=3, flatten=True)\n",
    "Y_train_conf = np.array(Y_train_conf).reshape(-1,1)\n",
    "Z_train_conf = np.array(Z_train_conf).reshape(-1,1)\n",
    "\n",
    "X_test_unconf = pd.read_csv(semisyn_data_dir + \"X_test_unconf.csv\")\n",
    "Y_test_unconf = pd.read_csv(semisyn_data_dir + \"Y_test_unconf.csv\")\n",
    "X_test_unconf = np.array(X_test_unconf)\n",
    "X_test_unconf = maxPooling_imgArr(X_test_unconf, kernel_size=3, flatten=True)\n",
    "Y_test_unconf = np.array(Y_test_unconf).reshape(-1,1)\n",
    "\n",
    "X_test_conf = pd.read_csv(semisyn_data_dir + \"X_test_conf.csv\")\n",
    "Y_test_conf = pd.read_csv(semisyn_data_dir + \"Y_test_conf.csv\")\n",
    "X_test_conf = np.array(X_test_conf)\n",
    "X_test_conf = maxPooling_imgArr(X_test_conf, kernel_size=3, flatten=True)\n",
    "Y_test_conf = np.array(Y_test_conf).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832003a1",
   "metadata": {},
   "source": [
    "2. Assign the key-value pair for each variable and prepare essential parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_train_data = {\"X\": X_train_conf,\n",
    "                   \"Y'\": Y_train_conf,\n",
    "                   \"Z\": Z_train_conf}\n",
    "n_bins = {\"Y'\": [0],\n",
    "          \"Z\": [0]}\n",
    "n_samples = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5302397a",
   "metadata": {},
   "source": [
    "3. Initialize a CW-GMM based deconfounding pipeline and fit a deconfounded KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a23911f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb34a3b32f1c4731828c2e0f85732a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CW-GMMs fitting:   0%|          | 0/2 [00:00<?, ?model/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4bc2b90a5d340bdb1e2ff7442e19e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EM iter:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b50f4d450154d43884f042c17fe67b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EM iter:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cwgmm_flow = cs_pipe.CausalGMMSampler(causal_graph=causal_graph,\n",
    "                                      cause_var_name=\"Y\",\n",
    "                                      effect_var_name=\"X\",\n",
    "                                      intv_values = np.unique(Y_train_conf),\n",
    "                                      data_dict = conf_train_data,\n",
    "                                      est_method = \"histogram\",\n",
    "                                      n_bins = n_bins\n",
    "                                    )\n",
    "\n",
    "cwgmm_model = cwgmm_flow.fit(comp_k = 1000,\n",
    "                             max_iter = 500,\n",
    "                             tol = 1e-3,\n",
    "                             init_method = \"kmeans++\",\n",
    "                             cov_type = \"diag\",\n",
    "                             cov_reg = 1e-6,\n",
    "                             min_variance_value = 1e-6,\n",
    "                             random_seed = None,\n",
    "                             weight_kernel = None,\n",
    "                             verbose = 2,\n",
    "                             return_model = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7a1ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "deconf_cwgmm_X, deconf_cwgmm_Y = cwgmm_flow.resample(n_samples = n_samples,\n",
    "                                                     shuffle = True,\n",
    "                                                     return_samples = True,\n",
    "                                                     random_seed = None)\n",
    "deconf_gmm_clf = cwgmm_flow.fit_deconf_model(ml_model = KNeighborsClassifier(n_neighbors = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756a0952",
   "metadata": {},
   "source": [
    "> Optional: You can save the fitted CW-GMM model easily for later resampling use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a715e3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at c:\\Users\\jxm1417\\Documents\\experiment_code\\causal_sampler\\package\\v0.0.1\\Tutorial\\frontdoor_cwgmm_model.pkl.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_0': {'base_model': <causal_sampler.gmmSampler.WeightedGMM at 0x2647c1c63d0>,\n",
       "  'intv_value': 1,\n",
       "  'hyperparams': {'K': 1000,\n",
       "   'cov_type': 'diag',\n",
       "   'cov_reg': 1e-06,\n",
       "   'min_variance_value': 1e-06,\n",
       "   'max_iter': 500,\n",
       "   'tol': 0.001,\n",
       "   'init_method': 'kmeans++',\n",
       "   'user_assigned_mus': None}},\n",
       " 'model_1': {'base_model': <causal_sampler.gmmSampler.WeightedGMM at 0x2647c1c6940>,\n",
       "  'intv_value': 2,\n",
       "  'hyperparams': {'K': 1000,\n",
       "   'cov_type': 'diag',\n",
       "   'cov_reg': 1e-06,\n",
       "   'min_variance_value': 1e-06,\n",
       "   'max_iter': 500,\n",
       "   'tol': 0.001,\n",
       "   'init_method': 'kmeans++',\n",
       "   'user_assigned_mus': None}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwgmm_model.save(\"frontdoor_cwgmm_model\")\n",
    "with open(\"frontdoor_cwgmm_model.pkl\", \"rb\") as f:\n",
    "    cwgmm_model_loaded = pickle.load(f)\n",
    "cwgmm_model_loaded.model_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15489091",
   "metadata": {},
   "source": [
    "4. Initialize a causal bootstrapping based deconfounding pipeline and fit a deconfounded KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9ea7410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6795bb27d7042b294972265d58d1cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CB Resampling:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cb_flow = cs_pipe.CausalBootstrapSampler(causal_graph=causal_graph,\n",
    "                                          cause_var_name=\"Y\",\n",
    "                                          effect_var_name=\"X\",\n",
    "                                          intv_values = np.unique(Y_train_conf),\n",
    "                                          data_dict = conf_train_data,\n",
    "                                          est_method = \"histogram\",\n",
    "                                          n_bins = n_bins)\n",
    "deconf_cb_X, deconf_cb_Y = cb_flow.resample(n_samples = n_samples,\n",
    "                                            kernel = None,\n",
    "                                            cb_mode = \"fast\",\n",
    "                                            shuffle = True,\n",
    "                                            return_samples = True,\n",
    "                                            random_seed = None,\n",
    "                                            verbose = 1)\n",
    "deconf_cb_clf = cb_flow.fit_deconf_model(ml_model = KNeighborsClassifier(n_neighbors = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e00acf7",
   "metadata": {},
   "source": [
    "5. Train another two KNNs using the original confounded dataset and the non-confounded (test) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48826d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonconf_clf = KNeighborsClassifier(n_neighbors = 3)\n",
    "nonconf_clf = nonconf_clf.fit(X_test_unconf, Y_test_unconf.reshape(-1))\n",
    "\n",
    "conf_clf = KNeighborsClassifier(n_neighbors = 3)\n",
    "conf_clf = conf_clf.fit(X_train_conf, Y_train_conf.reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6590bdac",
   "metadata": {},
   "source": [
    "6. compare thier performance on non-confounded and confounded test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "748dd950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on the non-confounded test set:\n",
      "Report of CW-GMM based deconfounded model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9366    0.9279    0.9322       430\n",
      "           2     0.9402    0.9475    0.9438       514\n",
      "\n",
      "    accuracy                         0.9386       944\n",
      "   macro avg     0.9384    0.9377    0.9380       944\n",
      "weighted avg     0.9385    0.9386    0.9385       944\n",
      "\n",
      "--------------------\n",
      "Report of CB-based deconfounded model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9340    0.9209    0.9274       430\n",
      "           2     0.9346    0.9455    0.9400       514\n",
      "\n",
      "    accuracy                         0.9343       944\n",
      "   macro avg     0.9343    0.9332    0.9337       944\n",
      "weighted avg     0.9343    0.9343    0.9343       944\n",
      "\n",
      "--------------------\n",
      "Report of non-confounded model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9423    0.9116    0.9267       430\n",
      "           2     0.9280    0.9533    0.9405       514\n",
      "\n",
      "    accuracy                         0.9343       944\n",
      "   macro avg     0.9352    0.9325    0.9336       944\n",
      "weighted avg     0.9345    0.9343    0.9342       944\n",
      "\n",
      "--------------------\n",
      "Report of confonded model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7143    0.6860    0.6999       430\n",
      "           2     0.7458    0.7704    0.7579       514\n",
      "\n",
      "    accuracy                         0.7320       944\n",
      "   macro avg     0.7300    0.7282    0.7289       944\n",
      "weighted avg     0.7314    0.7320    0.7315       944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test on the non-confounded test set:\")\n",
    "\n",
    "y_pred_gmm_deconf_unconf = deconf_gmm_clf.predict(X_test_unconf)\n",
    "print(\"Report of CW-GMM based deconfounded model:\")\n",
    "print(classification_report(Y_test_unconf, y_pred_gmm_deconf_unconf, digits=4))\n",
    "print(\"-\"*20)\n",
    "y_pred_cb_deconf_unconf = deconf_cb_clf.predict(X_test_unconf)\n",
    "print(\"Report of CB-based deconfounded model:\")\n",
    "print(classification_report(Y_test_unconf, y_pred_cb_deconf_unconf, digits=4))\n",
    "print(\"-\"*20)\n",
    "y_pred_unconf_unconf = nonconf_clf.predict(X_test_unconf)\n",
    "print(\"Report of non-confounded model:\")\n",
    "print(classification_report(Y_test_unconf, y_pred_unconf_unconf, digits=4))\n",
    "print(\"-\"*20)\n",
    "y_pred_conf_unconf = conf_clf.predict(X_test_unconf)\n",
    "print(\"Report of confonded model:\")\n",
    "print(classification_report(Y_test_unconf, y_pred_conf_unconf, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9902c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on the confounded test set:\n",
      "Report of deconfounded model using mechanism learning:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9565    0.9429    0.9496       490\n",
      "           2     0.9393    0.9537    0.9464       454\n",
      "\n",
      "    accuracy                         0.9481       944\n",
      "   macro avg     0.9479    0.9483    0.9480       944\n",
      "weighted avg     0.9482    0.9481    0.9481       944\n",
      "\n",
      "--------------------\n",
      "Report of deconfounded model using CB-based method:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9451    0.9490    0.9470       490\n",
      "           2     0.9447    0.9405    0.9426       454\n",
      "\n",
      "    accuracy                         0.9449       944\n",
      "   macro avg     0.9449    0.9448    0.9448       944\n",
      "weighted avg     0.9449    0.9449    0.9449       944\n",
      "\n",
      "--------------------\n",
      "Report of non-confounded model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9521    0.9327    0.9423       490\n",
      "           2     0.9289    0.9493    0.9390       454\n",
      "\n",
      "    accuracy                         0.9407       944\n",
      "   macro avg     0.9405    0.9410    0.9406       944\n",
      "weighted avg     0.9409    0.9407    0.9407       944\n",
      "\n",
      "--------------------\n",
      "Report of confonded model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9774    0.9694    0.9734       490\n",
      "           2     0.9672    0.9758    0.9715       454\n",
      "\n",
      "    accuracy                         0.9725       944\n",
      "   macro avg     0.9723    0.9726    0.9724       944\n",
      "weighted avg     0.9725    0.9725    0.9725       944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test on the confounded test set:\")\n",
    "\n",
    "y_pred_gmm_deconf_conf = deconf_gmm_clf.predict(X_test_conf)\n",
    "print(\"Report of deconfounded model using mechanism learning:\")\n",
    "print(classification_report(Y_test_conf, y_pred_gmm_deconf_conf, digits=4))\n",
    "print(\"-\"*20)\n",
    "y_pred_cb_deconf_conf = deconf_cb_clf.predict(X_test_conf)\n",
    "print(\"Report of deconfounded model using CB-based method:\")\n",
    "print(classification_report(Y_test_conf, y_pred_cb_deconf_conf, digits=4))\n",
    "print(\"-\"*20)\n",
    "y_pred_unconf_conf = nonconf_clf.predict(X_test_conf)\n",
    "print(\"Report of non-confounded model:\")\n",
    "print(classification_report(Y_test_conf, y_pred_unconf_conf, digits=4))\n",
    "print(\"-\"*20)\n",
    "y_pred_conf_conf = conf_clf.predict(X_test_conf)\n",
    "print(\"Report of confounded model:\")\n",
    "print(classification_report(Y_test_conf, y_pred_conf_conf, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_cb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
